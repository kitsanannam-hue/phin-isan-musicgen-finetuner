# Feature Specification: Thai Isan Lute (Phin) Music Transcription

**Feature Branch**: `001-phin-isan-transcription`
**Created**: 2025-11-29
**Status**: Draft
**Input**: User description: "‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠ Prompt ‡∏ó‡∏µ‡πà‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏•‡∏∞‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ñ‡∏∂‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ß‡πâ ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö AI Coding Agent ‡πÄ‡∏ä‡πà‡∏ô Replit Agents, GitHub Copilot, ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ AI ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î: ü§ñ Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Agent: ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ AI Transcription ‡∏û‡∏¥‡∏ì‡∏≠‡∏µ‡∏™‡∏≤‡∏ô (Phin Isan AI Dataset) ‡∏†‡∏≤‡∏£‡∏Å‡∏¥‡∏à (Goal): ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î Python ‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå AI Transcription ‡∏•‡∏≤‡∏¢‡∏û‡∏¥‡∏ì‡∏≠‡∏µ‡∏™‡∏≤‡∏ô ‡πÇ‡∏î‡∏¢‡πÄ‡∏ô‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies, ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Data Pipeline (Download & Preprocessing), ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (Model Stub) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å (References): ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡πâ‡∏î, Dependencies, ‡πÅ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ: quick_start_guide.md (Dependencies & Setup) youtube_sources.md (Download Script & URLs) training_pipeline.md (Feature Extraction & Evaluation) ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà Agent ‡∏ï‡πâ‡∏≠‡∏á‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£ (Actionable Steps): 1. Setup ‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies (‡πÑ‡∏ü‡∏•‡πå setup.py) ‡∏™‡∏£‡πâ‡∏≤‡∏á Environment ‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á pip install ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏ô ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1 ‡∏Ç‡∏≠‡∏á quick_start_guide.md (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ librosa, pretty_midi, yt-dlp, torch ‡∏´‡∏£‡∏∑‡∏≠ tensorflow, mir_eval, ‡∏Ø‡∏•‡∏Ø) ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÇ‡∏Ñ‡πâ‡∏î Python ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ GPU (CUDA) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏ô phin_dataset_master_guide.md (audio_sources/, sheet_music/, ‡∏Ø‡∏•‡∏Ø) 2. Data Pipeline: ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á (‡πÑ‡∏ü‡∏•‡πå data_pipeline.py) Batch Download Script: ‡∏ô‡∏≥‡πÇ‡∏Ñ‡πâ‡∏î Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏à‡∏≤‡∏Å "Batch Download Script" ‡πÉ‡∏ô youtube_sources.md ‡∏°‡∏≤‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 3 ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÅ‡∏£‡∏Å ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå .wav ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå audio_sources/ Feature Extraction (CQT): ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Python ‡∏ä‡∏∑‡πà‡∏≠ extract_phin_features(audio_path, sr=22050) ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô: ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á (librosa.load) ‡∏ó‡∏≥ Normalization ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏î‡πâ‡∏ß‡∏¢ Constant-Q Transform (CQT) ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ô training_pipeline.md (‡πÄ‡∏ô‡πâ‡∏ô‡∏ß‡πà‡∏≤ CQT ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà 12-TET) ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ CQT Spectrogram (NumPy Array) ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏• 3. Model Stubs ‡πÅ‡∏•‡∏∞ Evaluation (‡πÑ‡∏ü‡∏•‡πå model_core.py) Model Architecture Stub (PyTorch/TensorFlow): ‡∏™‡∏£‡πâ‡∏≤‡∏á Class/Stub ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ä‡∏∑‡πà‡∏≠ PhinTranscriber ‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏ï‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° CNN-RNN-Attention ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏ô training_pipeline.md (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î input_size ‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô ‡πÅ‡∏ï‡πà‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å ‡πÄ‡∏ä‡πà‡∏ô nn.Conv2d, nn.LSTM/nn.GRU, nn.Linear) Evaluation Function: ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡πÅ‡∏•‡∏∞‡∏ß‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô evaluate_transcription(...) ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ mir_eval.transcription ‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô "Evaluation Metrics" ‡∏Ç‡∏≠‡∏á training_pipeline.md ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏Ñ‡πà‡∏≤ Onset F1 ‡πÅ‡∏•‡∏∞ Pitch F1 (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏≠‡∏¥‡∏°‡∏û‡∏≠‡∏£‡πå‡∏ï mir_eval ‡πÅ‡∏•‡∏∞ pretty_midi) ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Python 3 ‡πÑ‡∏ü‡∏•‡πå (‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏ß‡∏°‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß) ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÇ‡∏Ñ‡πâ‡∏î‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠: setup.py data_pipeline.py model_core.py (‡∏£‡∏ß‡∏°‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Evaluation)"

## User Scenarios & Testing *(mandatory)*

### User Story 1 - Environment Setup and Dependencies Installation (Priority: P1)

Music researchers and AI developers want to set up a complete Python environment with all necessary dependencies for Thai Isan lute music transcription, including audio processing libraries, machine learning frameworks, and YouTube download tools.

**Why this priority**: This is the foundational requirement - without a properly configured environment, no other functionality can be implemented or tested. This enables all subsequent development work.

**Independent Test**: Can be fully tested by running the setup script and verifying that all required libraries (librosa, pretty_midi, torch/tensorflow, mir_eval, yt-dlp) are successfully installed and accessible.

**Acceptance Scenarios**:

1. **Given** a fresh Python environment, **When** the setup script is executed, **Then** all required dependencies are installed successfully
2. **Given** a system with GPU support, **When** environment setup is performed, **Then** the system detects and configures GPU support for faster processing

---

### User Story 2 - Thai Isan Music Data Collection and Preprocessing (Priority: P2)

Cultural preservationists and machine learning engineers want to automatically download authentic Thai Isan music videos from YouTube and convert them to audio files suitable for transcription model training, following the traditional 7-tone musical system.

**Why this priority**: This is essential for creating the training dataset - without quality Isan music samples, the transcription model cannot learn the unique characteristics of Phin lute music.

**Independent Test**: Can be tested by running the batch download script with YouTube URLs and verifying that the audio files are downloaded, converted to .wav format, and stored in the correct directory structure.

**Acceptance Scenarios**:

1. **Given** a list of YouTube URLs containing Isan music, **When** the batch download script executes, **Then** .wav files are saved to the audio_sources/ directory
2. **Given** downloaded audio files, **When** feature extraction runs, **Then** CQT spectrograms are generated that represent the unique characteristics of Thai Isan music

---

### User Story 3 - Music Transcription Model Framework (Priority: P3)

AI researchers and musicologists want a basic model architecture that can transcribe Thai Isan lute music using Constant-Q Transform features and appropriate evaluation metrics to measure transcription accuracy.

**Why this priority**: This provides the core functionality framework for music transcription, enabling evaluation of onset and pitch accuracy specific to Thai musical traditions.

**Independent Test**: Can be tested by running the evaluation function on sample transcriptions and verifying that Onset F1 and Pitch F1 metrics are calculated correctly.

**Acceptance Scenarios**:

1. **Given** audio input with Isan music, **When** PhinTranscriber processes the features, **Then** it produces MIDI-like output representing the played notes
2. **Given** transcription results, **When** evaluation function runs, **Then** it returns accurate Onset F1 and Pitch F1 scores

---

### Edge Cases

- What happens when the downloaded audio is corrupted or has very poor quality?
- How does the system handle different recording environments (studio vs. live performance)?
- What if the Constant-Q Transform fails on particularly complex polyphonic audio?

## Requirements *(mandatory)*

### Functional Requirements

- **FR-001**: System MUST install all required Python dependencies (librosa, pretty_midi, yt-dlp, torch/tensorflow, mir_eval, etc.)
- **FR-002**: System MUST detect and utilize available GPU resources for accelerated processing
- **FR-003**: System MUST create the appropriate directory structure (audio_sources/, sheet_music/, etc.) for organizing data
- **FR-004**: System MUST download YouTube videos and convert them to .wav format
- **FR-005**: System MUST extract Constant-Q Transform (CQT) features from audio files suitable for Thai Isan music transcription
- **FR-006**: System MUST provide a model architecture stub (PhinTranscriber) with CNN-RNN-Attention layers
- **FR-007**: System MUST implement evaluation functions to measure Onset F1 and Pitch F1 accuracy
- **FR-008**: The extract_phin_features function MUST return a normalized CQT spectrogram compatible with the model input

### Key Entities

- **Audio Source**: Raw audio files (in .wav format) extracted from YouTube videos containing Thai Isan lute music
- **CQT Feature**: Constant-Q Transform spectrogram representation of audio, optimized for non-12-TET musical systems like Thai traditional music
- **Transcription Output**: MIDI-like representation of detected musical notes with timing and pitch information
- **Model Architecture**: CNN-RNN-Attention framework designed for music transcription tasks with Thai Isan music characteristics

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: 100% of required dependencies are installed successfully in a fresh Python environment
- **SC-002**: At least 3 YouTube videos are successfully downloaded and converted to .wav format within 10 minutes
- **SC-003**: CQT feature extraction processes a 30-second audio clip in under 30 seconds with appropriate output dimensions
- **SC-004**: The PhinTranscriber model stub successfully accepts CQT spectrogram input and produces structured output
- **SC-005**: Evaluation functions return meaningful Onset F1 and Pitch F1 scores when comparing generated transcriptions to reference MIDI files