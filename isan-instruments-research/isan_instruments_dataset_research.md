# üìö ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ Isan Musical Instruments Classifier
## ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡∏ö‡∏Ñ‡πâ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å - ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 24 ‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô 2025

---

## üìã ‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç

1. [‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ](#‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ)
2. [‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏ô‡πä‡∏ï‡∏•‡∏≤‡∏¢‡∏û‡∏¥‡∏ì‡πÅ‡∏•‡∏∞‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÑ‡∏ó‡∏¢](#‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏ô‡πä‡∏ï‡∏•‡∏≤‡∏¢‡∏û‡∏¥‡∏ì‡πÅ‡∏•‡∏∞‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÑ‡∏ó‡∏¢)
3. [Datasets ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Music Transcription](#datasets-‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö-music-transcription)
4. [‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ Open Source ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏• AI](#‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ-open-source-‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•-ai)
5. [‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á](#‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á)
6. [‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ö‡∏ô YouTube](#‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ö‡∏ô-youtube)
7. [‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•](#‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•)
8. [‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô](#‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô)

---

## üéØ ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ

### ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå
‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏ö‡πâ‡∏≤‡∏ô‡∏≠‡∏µ‡∏™‡∏≤‡∏ô ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞:
- **‡∏û‡∏¥‡∏ì (Phin)** - ‡∏û‡∏¥‡∏ì‡∏™‡∏≤‡∏°‡∏™‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å‡πÄ‡∏â‡∏µ‡∏¢‡∏á‡πÄ‡∏´‡∏ô‡∏∑‡∏≠
- **‡πÅ‡∏Ñ‡∏ô (Khaen)** - ‡πÅ‡∏Ñ‡∏ô‡∏õ‡∏µ‡πà‡πÑ‡∏°‡πâ‡πÑ‡∏ú‡πà ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ä‡∏≤‡∏ï‡∏¥‡∏•‡∏≤‡∏ß

### ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏´‡∏•‡∏±‡∏Å
- Audio Processing: librosa, soundfile
- Machine Learning: scikit-learn (Random Forest)
- Feature Engineering: MFCC, Chroma, Spectral Analysis
- Web Interface: Streamlit
- Visualization: Plotly, Matplotlib, Seaborn

---

## üéµ ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏ô‡πä‡∏ï‡∏•‡∏≤‡∏¢‡∏û‡∏¥‡∏ì‡πÅ‡∏•‡∏∞‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÑ‡∏ó‡∏¢

### 1. ‡πÇ‡∏ô‡πä‡∏ï‡∏•‡∏≤‡∏¢‡∏û‡∏¥‡∏ì‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
**‡πÅ‡∏´‡∏•‡πà‡∏á:** guitar285.wordpress.com

#### ‡∏•‡∏≤‡∏¢‡∏û‡∏¥‡∏ì‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏° (Pentatonic Scale):

**‡∏•‡∏≤‡∏¢‡∏ô‡∏Å‡πÑ‡∏™‡πà‡∏ö‡∏¥‡∏ô‡∏Ç‡πâ‡∏≤‡∏°‡∏ó‡∏∏‡πà‡∏á**
```
* / ‡∏° ‡∏ã ‡∏• ‡∏• ‡∏î ‡∏ã ‡∏• / ‡∏° ‡∏ã ‡∏• ‡∏• ‡∏î ‡∏ã ‡∏• / 
‡∏î ‡∏£ ‡∏° ‡∏° ‡∏ã ‡∏£ ‡∏° / ‡∏î ‡∏£ ‡∏° ‡∏° ‡∏ã ‡∏£ ‡∏° / 
‡∏° ‡∏ã ‡∏• ‡∏• ‡∏î ‡∏ã ‡∏• / ‡∏° ‡∏ã ‡∏• ‡∏• ‡∏î ‡∏ã ‡∏• / 
‡∏° ‡∏£ ‡∏î ‡∏• ‡∏î ‡∏ã ‡∏• / ‡∏° ‡∏£ ‡∏î ‡∏• ‡∏î ‡∏ã ‡∏• / 
(‡∏ã‡πâ‡∏≥ * 5 ‡∏£‡∏≠‡∏ö)
```

**‡∏•‡∏≤‡∏¢‡πÅ‡∏°‡∏•‡∏á‡∏†‡∏π‡πà‡∏ï‡∏≠‡∏°‡∏î‡∏≠‡∏Å‡πÑ‡∏°‡πâ**
```
(‡πÄ‡∏Å‡∏£‡∏¥‡πà‡∏ô) ‡∏î . . . . ./ ‡∏£ . . . . ./ ‡∏° . . . . ./
* / ‡∏• ‡∏• ‡∏• / ‡∏• ‡∏° / ‡∏° ‡∏ã ‡∏° / ‡∏£ ‡∏° ‡∏ã ‡∏° /
‡∏• ‡∏• ‡∏• / ‡∏• ‡∏£ / ‡∏î ‡∏£ ‡∏° ‡∏£ ‡∏î / ‡∏• ‡∏î ‡∏• ‡∏° /
(‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ã‡πâ‡∏≥ *)
```

**‡∏•‡∏≤‡∏¢‡πÇ‡∏õ‡∏á‡∏•‡∏≤‡∏á**
```
* / ‡∏° ‡∏ã ‡∏• ‡∏ã ‡∏• / ‡∏• ‡∏î ‡∏• ‡∏ã ‡∏• / 
‡∏î ‡∏£ ‡∏° ‡∏£ ‡∏° / ‡∏• ‡∏ã ‡∏° ‡∏£ ‡∏° / 
‡∏° ‡∏ã ‡∏• ‡∏ã ‡∏• / ‡∏£ ‡∏î ‡∏• ‡∏ã ‡∏• /
(‡∏ã‡πâ‡∏≥ * 5 ‡∏£‡∏≠‡∏ö)
```

**‡∏•‡∏≤‡∏¢‡πÄ‡∏ã‡∏¥‡πâ‡∏á‡∏ö‡∏±‡πâ‡∏á‡πÑ‡∏ü**
```
* / ‡∏• ‡∏î ‡∏• ‡∏î ‡∏• ‡∏î ‡∏• / ‡∏• ‡∏î ‡∏• ‡∏î ‡∏• ‡∏î ‡∏• / 
‡∏• ‡∏î ‡∏• ‡∏î ‡∏£ ‡∏î ‡∏• / ‡∏£ ‡∏î ‡∏£ ‡∏î ‡∏£ ‡∏î ‡∏• /
‡∏° ‡∏£ ‡∏° ‡∏£ ‡∏° ‡∏î ‡∏£ / ‡∏° ‡∏£ ‡∏° ‡∏£ ‡∏° ‡∏î ‡∏£ /
(‡∏ã‡πâ‡∏≥ * 5 ‡∏£‡∏≠‡∏ö)
```

**‡∏•‡∏≤‡∏¢‡πÄ‡∏ï‡πâ‡∏¢‡πÇ‡∏Ç‡∏á**
```
* / ‡∏• ‡∏ã ‡∏° ‡∏• / ‡∏ã ‡∏î ‡∏• ‡∏ã ‡∏• ‡∏° / 
‡∏• ‡∏ã ‡∏° ‡∏• / ‡∏ã ‡∏î ‡∏° ‡∏• / 
‡∏ã ‡∏î ‡∏• ‡∏ã ‡∏° ‡∏• / ‡∏ã ‡∏° ‡∏£ ‡∏î ‡∏° /
(‡∏ã‡πâ‡∏≥ * 5 ‡∏£‡∏≠‡∏ö)
```

#### ‡∏£‡∏∞‡∏ö‡∏ö‡πÇ‡∏ô‡πä‡∏ï‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÑ‡∏ó‡∏¢
- **Scale:** ‡∏£‡∏∞‡∏ö‡∏ö 7 ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡πÜ ‡∏Å‡∏±‡∏ô (7-tone equidistant)
- **‡πÇ‡∏ã‡∏•‡∏ü‡∏≤‡πÑ‡∏ó‡∏¢:** ‡∏î ‡∏£ ‡∏° ‡∏ü ‡∏ã ‡∏• ‡∏ó
- **‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å Western:** ‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å‡πÉ‡∏ä‡πâ 12 ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡πà‡∏≠ octave
- **Pentatonic (5 ‡πÄ‡∏™‡∏µ‡∏¢‡∏á):** ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏û‡∏•‡∏á‡πÑ‡∏ó‡∏¢‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà

### 2. ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏•‡∏≤‡∏¢‡∏û‡∏¥‡∏ì
**‡∏ä‡∏∑‡πà‡∏≠:** "‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏•‡∏≤‡∏¢‡∏û‡∏¥‡∏ì‡πÉ‡∏ô‡∏ß‡∏±‡∏í‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô ‡∏Å‡∏£‡∏ì‡∏µ‡∏®‡∏∂‡∏Å‡∏©‡∏≤: ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ"
**‡∏ú‡∏π‡πâ‡∏ß‡∏¥‡∏à‡∏±‡∏¢:** ‡∏ò‡∏á‡πÑ‡∏ó ‡∏à‡∏±‡∏ô‡πÄ‡∏ï (2554)
**‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô:** ‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏ö‡∏π‡∏£‡∏û‡∏≤

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:**
- ‡∏û‡∏¥‡∏ì‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡∏ö‡∏≤‡∏•‡∏µ-‡∏™‡∏±‡∏ô‡∏™‡∏Å‡∏§‡∏ï "‡∏ß‡∏µ‡∏ì‡∏≤"
- ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÉ‡∏ô‡πÑ‡∏ó‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 1,000 ‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß
- ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 200 ‡∏õ‡∏µ
- ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏à‡∏≤‡∏Å‡∏û‡∏¥‡∏ì‡∏™‡∏≠‡∏á‡∏™‡∏≤‡∏¢ ‚Üí ‡∏™‡∏≤‡∏°‡∏™‡∏≤‡∏¢ ‚Üí ‡∏™‡∏µ‡πà‡∏™‡∏≤‡∏¢
- **‡∏ö‡∏±‡∏ô‡πÑ‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á:** Pentatonic Scale ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å
- **‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:** ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏£‡πÄ‡∏•‡∏á‡πÅ‡∏ö‡∏ö improvisation (‡∏î‡πâ‡∏ô‡∏™‡∏î) ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ Jazz

**‡∏•‡∏≤‡∏¢‡∏û‡∏¥‡∏ì‡∏ó‡∏µ‡πà‡∏®‡∏∂‡∏Å‡∏©‡∏≤:**
1. ‡∏•‡∏≤‡∏¢‡∏Å‡∏≤‡πÄ‡∏ï‡πâ‡∏ô‡∏Å‡πâ‡∏≠‡∏ô
2. ‡∏•‡∏≤‡∏¢‡∏õ‡∏π‡πà‡∏õ‡πã‡∏≤‡∏´‡∏•‡∏≤‡∏ô
3. ‡∏•‡∏≤‡∏¢‡∏•‡∏≥‡πÄ‡∏û‡∏•‡∏¥‡∏ô
4. ‡∏•‡∏≤‡∏¢‡∏°‡πÇ‡∏´‡∏£‡∏µ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô

---

## üìä Datasets ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Music Transcription

### 1. NSynth Dataset (Google Magenta)
- **‡∏Ç‡∏ô‡∏≤‡∏î:** 305,979 musical notes
- **‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏ô‡∏ï‡∏£‡∏µ:** 1,006 instruments
- **‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥:** ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏ô‡πä‡∏ï‡∏°‡∏µ unique pitch, timbre, envelope
- **‡∏•‡∏¥‡∏á‡∏Å‡πå:** https://magenta.withgoogle.com/datasets/nsynth
- **‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î:** ‡∏°‡∏∏‡πà‡∏á‡πÄ‡∏ô‡πâ‡∏ô‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å (12-tone system)

### 2. OpenMIC-2018
- **‡∏Ç‡∏ô‡∏≤‡∏î:** 20,000 audio clips (10 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏ï‡πà‡∏≠‡∏Ñ‡∏•‡∏¥‡∏õ)
- **‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤:** Free Music Archive (Creative Commons)
- **Labels:** Multi-instrument recognition
- **‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Instruments:** 8-10 classes
- **‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î:** 
  - GitHub: https://github.com/cosmir/openmic-2018
  - Zenodo: https://zenodo.org/records/1432913
- **‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:** Open source, crowd-sourced labels

### 3. FMA (Free Music Archive)
- **‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:** 917 GiB
- **‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏û‡∏•‡∏á:** 106,574 tracks
- **Metadata:** ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏•‡∏á, ‡∏≠‡∏±‡∏•‡∏ö‡∏±‡πâ‡∏°, ‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô, ‡πÅ‡∏ô‡∏ß, tags, description
- **Subsets:**
  - **fma_small:** 8,000 tracks (30 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ, 8 genres) - 7.2 GiB
  - **fma_medium:** 25,000 tracks - 25 GiB  
  - **fma_large:** 106,574 tracks - 93 GiB
  - **fma_full:** ‡∏û‡∏£‡πâ‡∏≠‡∏° full-length audio - 917 GiB
- **‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î:**
  - GitHub: https://github.com/mdeff/fma
  - Kaggle: https://www.kaggle.com/datasets/imsparsh/fma-free-music-archive-small-medium
  - Hugging Face: https://huggingface.co/datasets/benjamin-paine/free-music-archive-full
- **‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå:** ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö genre classification ‡πÅ‡∏•‡∏∞ instrument recognition

### 4. MusicNet
- **‡∏Ç‡∏ô‡∏≤‡∏î:** 330 recordings of classical music
- **‡∏Ñ‡∏µ‡∏¢‡πå:** 10 composers, 11 instruments
- **Labels:** Over 1 million annotated labels (frame-level)
- **‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:** frame-level timbre transcription
- **‡∏•‡∏¥‡∏á‡∏Å‡πå:** https://benadar293.github.io/

### 5. Slakh2100 Dataset
- **‡∏Ç‡∏ô‡∏≤‡∏î:** 2,100 tracks
- **‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥:** Multi-track, synthesized music
- **‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°:**
  - Music Instrument Recognition
  - Automatic Music Transcription (AMT)
  - Music Source Separation (MSS)
- **GitHub:** https://github.com/KinWaiCheuk/slakh_loader

### 6. HamNava Dataset (Persian/Iranian Music)
- **‡∏Ç‡∏ô‡∏≤‡∏î:** 6,000 audio excerpts
- **‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥:** Multi-label instrument classification
- **‡∏£‡∏∞‡∏ö‡∏ö:** Dastgah (modal system ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÑ‡∏ó‡∏¢)
- **‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:** ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡∏µ ‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö non-Western music
- **‡∏•‡∏¥‡∏á‡∏Å‡πå:** https://transactions.ismir.net/articles/10.5334/tismir.257

### 7. GigaMIDI Dataset
- **‡∏Ç‡∏ô‡∏≤‡∏î:** 1.4 ‡∏•‡πâ‡∏≤‡∏ô MIDI files
- **‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤:** Internet Archive
- **‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå:** symbolic music representation
- **‡∏•‡∏¥‡∏á‡∏Å‡πå:** https://transactions.ismir.net/articles/10.5334/tismir.203

---

## üõ†Ô∏è ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ Open Source ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏• AI

### 1. Spotify Basic Pitch ‚≠ê (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
**GitHub:** https://github.com/spotify/basic-pitch

**‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥:**
- Lightweight neural network ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Audio-to-MIDI
- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö pitch bend detection
- Instrument-agnostic (‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢)
- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö polyphonic instruments
- ‡∏°‡∏µ Web Demo: https://basicpitch.spotify.com/

**Model Formats:**
- TensorFlow (original)
- CoreML (MacOS)
- TensorFlowLite (Linux)
- ONNX (Windows)

**‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á:**
```bash
pip install basic-pitch
```

**‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:**
```python
from basic_pitch.inference import predict
from basic_pitch import ICASSP_2022_MODEL_PATH

model_output, midi_data, note_events = predict(<audio_path>)
```

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
- ‡πÄ‡∏•‡πá‡∏Å‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡πá‡∏ß
- ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢
- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢ platform
- Pitch bend ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á Western scale

### 2. Omnizart
**GitHub:** https://github.com/Music-and-Culture-Technology-Lab/omnizart
**Documentation:** https://music-and-culture-technology-lab.github.io/omnizart-doc/

**‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥:**
- Python library ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö automatic music transcription
- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó:
  - Pitched instruments
  - Vocal melody  
  - Chord transcription
  - Drum event detection
- ‡∏°‡∏µ pre-trained models

**‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á:**
```bash
pip install omnizart
```

### 3. MT3 (Google Magenta)
**‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î:** Multi-Task Multitrack Music Transcription
**GitHub:** https://github.com/google/flax/discussions/1664

**‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥:**
- Unified training framework
- Multi-instrument transcription
- Transformer-based architecture
- High-quality results

### 4. YourMT3+
**Paper:** https://arxiv.org/html/2407.04822v1

**‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥:**
- Enhanced multi-instrument transcription
- Language token decoding approach
- ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏à‡∏≤‡∏Å MT3

### 5. NeuralNote (VST Plugin)
**GitHub:** https://github.com/DamRsn/NeuralNote

**‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥:**
- Audio plugin ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DAW
- ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: VST3, Component, Standalone
- Real-time transcription
- ‡πÉ‡∏ä‡πâ Basic Pitch ‡∏†‡∏≤‡∏¢‡πÉ‡∏ï‡πâ‡∏ù‡∏≤‡∏Å‡∏£‡∏∞‡πÇ‡∏õ‡∏£‡∏á

### 6. ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢ KMUTT (‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏û‡∏£‡∏∞‡∏à‡∏≠‡∏°‡πÄ‡∏Å‡∏•‡πâ‡∏≤‡∏ò‡∏ô‡∏ö‡∏∏‡∏£‡∏µ)
**‡∏ä‡∏∑‡πà‡∏≠:** "Automatic Music Transcription for Thai Xylophone"
**‡∏•‡∏¥‡∏á‡∏Å‡πå:** https://inc.kmutt.ac.th/download/capstone_design_projects/2567/10.pdf

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£:**
- Energy-based approach
- Spectral Analysis (EWMA, FFT, Peak Detection)
- **‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà deep learning**

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**
- **Onset detection F1-score:** 98.54%
- **Pitch detection F1-score:** 97.34%
- ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ deep learning models (Onsets and Frames)
- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ö‡∏ô embedded devices ‡πÑ‡∏î‡πâ

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
- ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö real-time processing
- ‡πÉ‡∏ä‡πâ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≠‡∏¢
- ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÑ‡∏ó‡∏¢

---

## üìñ ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á

### 1. ‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞ AI Bias
**‡∏ä‡∏∑‡πà‡∏≠:** "Stepping Towards Transcultural Machine Learning in Music" 
**‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏ó‡∏≥:** Google Magenta
**‡∏•‡∏¥‡∏á‡∏Å‡πå:** https://magenta.withgoogle.com/transcultural

**‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:**
- AI models ‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å (12-tone)
- ‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÑ‡∏ó‡∏¢‡πÉ‡∏ä‡πâ 7-tone equidistant system
- ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ dataset ‡πÅ‡∏•‡∏∞ model ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏£‡∏∞‡∏ö‡∏ö‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞:**
- ‡∏™‡∏£‡πâ‡∏≤‡∏á training data ‡∏à‡∏≤‡∏Å‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÑ‡∏ó‡∏¢
- Retrain ‡∏´‡∏£‡∏∑‡∏≠ fine-tune models
- ‡∏û‡∏±‡∏í‡∏ô‡∏≤ evaluation metrics ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

### 2. Deep Learning ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÑ‡∏ó‡∏¢
**‡∏ä‡∏∑‡πà‡∏≠:** "Deep Learning for Music Genre Classification: Thai Music"
**‡∏•‡∏¥‡∏á‡∏Å‡πå:** https://dl.acm.org/doi/full/10.1145/3722150.3722157

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£:**
- CNN ‡πÅ‡∏•‡∏∞ RNN
- ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏û‡∏•‡∏á‡πÑ‡∏ó‡∏¢

### 3. Thai Tuning System Studies
**‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:**
- "The Myth of Equidistance in Thai Tuning"
- "Equiheptatonic Tuning in Thai Classical Music"
- "Relative Nature of Thai Traditional Music through its Tuning System"

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö:**
- ‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô 7-tone equidistant (‡∏ó‡∏§‡∏©‡∏é‡∏µ)
- ‡πÉ‡∏ô‡∏ó‡∏≤‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏ú‡∏±‡∏ô (variations)
- Pitch intervals ‡πÑ‡∏°‡πà‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏ó‡∏∏‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏ô‡∏ï‡∏£‡∏µ
- ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏ï‡∏≤‡∏°‡∏†‡∏π‡∏°‡∏¥‡∏†‡∏≤‡∏Ñ‡πÅ‡∏•‡∏∞‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô

---

## üé• ‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ö‡∏ô YouTube

### 1. Tutorial Channels (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Training Data)

**‡∏°‡∏π‡∏ô‡∏°‡∏±‡∏á‡∏≠‡∏µ‡∏™‡∏≤‡∏ô Channel**
- ‡∏™‡∏≠‡∏ô‡∏û‡∏¥‡∏ì‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏•‡∏≤‡∏¢
- ‡∏°‡∏µ‡πÇ‡∏ô‡πä‡∏ï‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö
- ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà
- ‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: https://www.youtube.com/watch?v=-l1Pj7N_eI8

**‡∏î‡∏∏‡∏•‡∏¢‡πå‡πÄ‡∏û‡∏•‡∏á‡∏û‡∏¥‡∏ì**
- ‡∏™‡∏≠‡∏ô‡∏û‡∏¥‡∏ì‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
- ‡∏•‡∏≤‡∏¢‡∏û‡∏¥‡∏ì‡∏ï‡πà‡∏≤‡∏á ‡πÜ
- ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏≥‡πÇ‡∏ô‡πä‡∏ï
- ‡∏•‡∏¥‡∏á‡∏Å‡πå: https://www.youtube.com/watch?v=_Mm7gnrdy08

**‡∏ê‡∏¥‡∏ï‡∏¥‡∏ß‡∏±‡∏™‡∏™‡πå ‡∏ó‡∏≠‡∏á‡∏≠‡πà‡∏≠‡∏ô (‡∏™‡∏ï‡∏µ‡∏ü)**
- ‡∏™‡∏≠‡∏ô‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
- ‡∏°‡∏µ‡πÇ‡∏ô‡πä‡∏ï‡∏û‡∏¥‡∏ì‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏∏‡∏î
- ‡∏£‡∏ß‡∏°‡πÇ‡∏ô‡πä‡∏ï‡∏û‡∏¥‡∏ì 7 ‡∏•‡∏≤‡∏¢, 8 ‡∏•‡∏≤‡∏¢, 23 ‡∏•‡∏≤‡∏¢
- Website: https://sites.google.com/view/stevethitiwat

**‡∏´‡∏ô‡∏¥‡∏á ‡∏ã‡∏¥‡∏á‡∏Å‡∏¥ ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ö‡∏£‡∏£‡πÄ‡∏•‡∏á**
- ‡∏•‡∏≤‡∏¢‡∏°‡πÇ‡∏´‡∏£‡∏µ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô
- performance review
- ‡∏•‡∏¥‡∏á‡∏Å‡πå: https://www.youtube.com/watch?v=daZpyFy1Qb8

**M MUSIC GROUP**
- ‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô
- ‡∏•‡∏≤‡∏¢‡∏û‡∏¥‡∏ì‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
- ‡∏°‡∏µ‡πÇ‡∏ô‡πä‡∏ï‡πÅ‡∏•‡∏∞‡∏ã‡∏≤‡∏ß‡∏î‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö

### 2. ‡∏•‡∏≤‡∏¢‡∏û‡∏¥‡∏ì‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô YouTube
1. ‡∏•‡∏≤‡∏¢‡∏•‡∏≥‡πÄ‡∏û‡∏•‡∏¥‡∏ô
2. ‡∏•‡∏≤‡∏¢‡πÅ‡∏´‡πà (‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö)
3. ‡∏•‡∏≤‡∏¢‡πÄ‡∏•‡∏≤‡∏∞‡∏ö‡πâ‡∏≤‡∏ô
4. ‡∏•‡∏≤‡∏¢‡∏°‡πÇ‡∏´‡∏£‡∏µ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô
5. ‡∏•‡∏≤‡∏¢‡πÇ‡∏õ‡∏á‡∏•‡∏≤‡∏á
6. ‡∏•‡∏≤‡∏¢‡πÄ‡∏ï‡πâ‡∏¢
7. ‡∏•‡∏≤‡∏¢‡∏õ‡∏π‡πà‡∏õ‡πã‡∏≤‡∏´‡∏•‡∏≤‡∏ô
8. ‡∏•‡∏≤‡∏¢‡πÅ‡∏°‡∏á‡∏ï‡∏±‡∏ö‡πÄ‡∏ï‡πà‡∏≤

### 3. ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

**‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠:**
```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á yt-dlp
pip install yt-dlp

# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á
yt-dlp -x --audio-format wav <youtube_url>

# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î playlist
yt-dlp -x --audio-format wav <playlist_url>
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô Project:**
```python
# examples/download_youtube_videos.py
from src.data_collection.youtube_downloader import YouTubeDownloader

downloader = YouTubeDownloader()
downloader.download_audio(url, output_path)
```

---

## üî¨ ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•

### Pipeline ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥

#### 1. Data Collection Phase
```
1. ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏à‡∏≤‡∏Å YouTube
   - ‡πÉ‡∏ä‡πâ yt-dlp
   - ‡πÅ‡∏¢‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô WAV (22,050 Hz)
   - ‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏ï‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏ô‡∏ï‡∏£‡∏µ

2. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metadata
   - ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏•‡∏á/‡∏•‡∏≤‡∏¢
   - ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏ô‡∏ï‡∏£‡∏µ  
   - ‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô
   - consent status
   - cultural attribution

3. ‡∏™‡∏£‡πâ‡∏≤‡∏á ground truth
   - ‡πÉ‡∏ä‡πâ Basic Pitch ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô MIDI
   - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
   - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å annotations
```

#### 2. Data Preprocessing
```python
# ‡πÉ‡∏ä‡πâ AudioProcessor ‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ
from src.preprocessing.audio_processor import AudioProcessor

processor = AudioProcessor(target_sr=22050)

# 1. ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞ normalize
audio, sr, quality = processor.preprocess_audio(file_path)

# 2. ‡πÅ‡∏ö‡πà‡∏á segments (3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ, overlap 50%)
segments = processor.extract_segments(audio, sr, segment_duration=3.0)

# 3. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û
if not quality['is_valid']:
    print(f"Audio issue: {quality.get('reason')}")
```

#### 3. Feature Extraction
```python
from src.features.feature_extractor import FeatureExtractor

extractor = FeatureExtractor(sr=22050)

# ‡πÅ‡∏ï‡∏Å features ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (143 features)
features = extractor.extract_all_features(audio)

# Features ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó:
# - MFCCs (20 coefficients √ó 4 statistics = 80 features)
# - Chroma (12 bins √ó 4 statistics = 48 features)
# - Spectral (centroid, rolloff, bandwidth)
# - Temporal (zero-crossing rate, RMS)
# - Pitch (fundamental frequency analysis)
```

#### 4. Model Training
```python
from src.models.classifier import InstrumentClassifier

# Random Forest Classifier
classifier = InstrumentClassifier(
    n_estimators=100,
    random_state=42
)

# Train
results = classifier.train(X, y, validation_split=0.2)

# Metrics
print(f"Accuracy: {results['train_accuracy']:.2%}")
print(f"Val Accuracy: {results['validation_accuracy']:.2%}")
print(f"CV Mean: {results['cv_mean']:.2%}")
```

#### 5. Evaluation
```python
from src.evaluation.model_evaluator import ModelEvaluator

evaluator = ModelEvaluator()

# Confusion Matrix
evaluator.plot_confusion_matrix(y_true, y_pred, labels)

# Feature Importance
importance = classifier.get_feature_importance(feature_names, top_n=20)
```

### ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Transcription

#### Option 1: ‡πÉ‡∏ä‡πâ Basic Pitch (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô)
```python
from basic_pitch.inference import predict
from basic_pitch import ICASSP_2022_MODEL_PATH

# ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏¥‡∏ì‡πÄ‡∏õ‡πá‡∏ô MIDI
model_output, midi_data, note_events = predict(
    "audio/phin_sample.wav"
)

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å MIDI
midi_data.write("output/phin_transcription.mid")

# ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå note events
for note in note_events:
    print(f"Pitch: {note['pitch']}, "
          f"Start: {note['start_time']}, "
          f"Duration: {note['duration']}")
```

#### Option 2: ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ KMUTT (Energy + Spectral)
```python
# Onset Detection (EWMA)
def detect_onsets_ewma(audio, threshold=0.3):
    # Energy calculation
    energy = librosa.feature.rms(y=audio)[0]
    
    # EWMA smoothing
    alpha = 0.1
    smoothed = np.zeros_like(energy)
    smoothed[0] = energy[0]
    for i in range(1, len(energy)):
        smoothed[i] = alpha * energy[i] + (1 - alpha) * smoothed[i-1]
    
    # Peak detection
    onsets = librosa.util.peak_pick(
        smoothed, 
        pre_max=3, 
        post_max=3, 
        pre_avg=3, 
        post_avg=5, 
        delta=threshold, 
        wait=10
    )
    return onsets

# Pitch Detection (FFT)
def detect_pitch_fft(audio_segment, sr=22050):
    # FFT
    fft = np.fft.fft(audio_segment)
    magnitude = np.abs(fft)
    
    # Find peak
    peak_idx = np.argmax(magnitude)
    frequency = peak_idx * sr / len(audio_segment)
    
    return frequency
```

### ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•

#### Metrics ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Classification
```python
from sklearn.metrics import (
    accuracy_score, 
    precision_recall_fscore_support,
    confusion_matrix
)

# Overall metrics
accuracy = accuracy_score(y_true, y_pred)
precision, recall, f1, _ = precision_recall_fscore_support(
    y_true, y_pred, average='weighted'
)

# Per-class metrics
conf_matrix = confusion_matrix(y_true, y_pred)
```

#### Metrics ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Transcription
```python
import mir_eval

# Onset detection
onset_precision, onset_recall, onset_f1 = mir_eval.onset.f_measure(
    reference_onsets, estimated_onsets, window=0.05
)

# Note transcription
note_precision, note_recall, note_f1 = mir_eval.transcription.precision_recall_f1_overlap(
    reference_intervals, reference_pitches,
    estimated_intervals, estimated_pitches
)

# Pitch accuracy
pitch_accuracy = mir_eval.melody.voicing_measures(
    reference_pitches, estimated_pitches
)
```

---

## üìÅ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô

### ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ
```
kritsanan1-isan-instruments/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_collection/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ youtube_downloader.py      # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å YouTube
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ audio_processor.py         # ‡πÇ‡∏´‡∏•‡∏î, normalize, segment
‚îÇ   ‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_extractor.py       # MFCC, Chroma, Spectral
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classifier.py              # Random Forest
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataset_manager.py         # Metadata management
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_evaluator.py         # Metrics, plots
‚îÇ   ‚îî‚îÄ‚îÄ transcription/
‚îÇ       ‚îú‚îÄ‚îÄ music_transcriber.py       # Transcription logic
‚îÇ       ‚îú‚îÄ‚îÄ onset_detector.py          # Onset detection
‚îÇ       ‚îî‚îÄ‚îÄ pitch_detector.py          # Pitch detection
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                           # Original recordings
‚îÇ   ‚îú‚îÄ‚îÄ processed/                     # Preprocessed audio
‚îÇ   ‚îî‚îÄ‚îÄ metadata/                      # JSON metadata
‚îú‚îÄ‚îÄ models/                            # Trained models
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ METHODOLOGY.md                 # Technical methodology
‚îÇ   ‚îú‚îÄ‚îÄ DATA_COLLECTION_PROTOCOL.md    # Ethical guidelines
‚îÇ   ‚îú‚îÄ‚îÄ THAI_MUSIC_SYSTEM.md           # Thai music theory
‚îÇ   ‚îî‚îÄ‚îÄ TRANSCRIPTION_GUIDE.md         # Transcription guide
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îú‚îÄ‚îÄ download_youtube_videos.py
‚îÇ   ‚îú‚îÄ‚îÄ generate_demo_data.py
‚îÇ   ‚îî‚îÄ‚îÄ transcribe_demo.py
‚îú‚îÄ‚îÄ app.py                             # Streamlit web app
‚îî‚îÄ‚îÄ train_model.py                     # Training pipeline
```

### Dependencies
```python
# pyproject.toml
dependencies = [
    "joblib>=1.5.2",
    "librosa>=0.11.0",
    "matplotlib>=3.10.7",
    "mir-eval>=0.8.2",
    "numpy>=2.3.5",
    "pandas>=2.3.3",
    "plotly>=6.5.0",
    "pretty-midi>=0.2.11",
    "scikit-learn>=1.7.2",
    "seaborn>=0.13.2",
    "soundfile>=0.13.1",
    "streamlit>=1.51.0",
    "yt-dlp>=2025.11.12",
]
```

### Features Extracted (143 total)

#### 1. MFCCs (80 features)
- 20 coefficients
- 4 statistics each (mean, std, max, min)
- Captures timbral characteristics

#### 2. Chroma Features (48 features)
- 12 bins (musical notes)
- 4 statistics each
- Represents pitch content

#### 3. Spectral Features (12 features)
- Spectral Centroid (brightness)
- Spectral Rolloff (frequency distribution)
- Spectral Bandwidth (frequency range)
- 4 statistics each

#### 4. Temporal Features (2 features)
- Zero-crossing rate
- RMS energy

#### 5. Pitch Features (1 feature)
- Fundamental frequency

### Ethical Framework

#### Consent Protocol
```python
# dataset_manager.py
dataset_manager.add_recording(
    file_path="audio/phin_sample.wav",
    instrument="Phin",
    technique="Traditional",
    performer_name="‡∏ô‡∏≤‡∏¢‡∏ó‡∏≠‡∏á‡πÉ‡∏™ ‡∏ó‡∏±‡∏ö‡∏ñ‡∏ô‡∏ô",
    consent_status=True,              # Required!
    cultural_attribution="‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô‡∏≠‡∏µ‡∏™‡∏≤‡∏ô",
    notes="‡∏•‡∏≤‡∏¢‡∏•‡∏≥‡πÄ‡∏û‡∏•‡∏¥‡∏ô"
)

# Validate consent before training
consent_stats = dataset_manager.validate_consent()
if consent_stats['consent_rate'] < 1.0:
    print("‚ö†Ô∏è Not all recordings have consent!")
```

#### Cultural Respect Guidelines
1. ‚úÖ Documented performer consent required
2. ‚úÖ Proper cultural attribution
3. ‚úÖ Transparent methodology
4. ‚úÖ Community engagement
5. ‚úÖ Maintain cultural context
6. ‚ùå No commercial exploitation without consent
7. ‚ùå No cultural appropriation
8. ‚ùå No misrepresentation of traditions

---

## üéØ ‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥

### Phase 1: Data Collection (2-4 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå)
1. ‚úÖ ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏° YouTube links (‡∏ó‡∏≥‡πÅ‡∏•‡πâ‡∏ß - ‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô)
2. ‚è≥ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠/‡πÄ‡∏™‡∏µ‡∏¢‡∏á (‡πÉ‡∏ä‡πâ yt-dlp)
3. ‚è≥ ‡πÅ‡∏¢‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô WAV 22,050 Hz
4. ‚è≥ ‡∏™‡∏£‡πâ‡∏≤‡∏á metadata (‡∏ä‡∏∑‡πà‡∏≠, ‡∏•‡∏≤‡∏¢, ‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô)
5. ‚è≥ ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• consent (‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô/‡∏ä‡πà‡∏≠‡∏á)

**Target:** 100-200 samples ‡∏ï‡πà‡∏≠‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏ô‡∏ï‡∏£‡∏µ

### Phase 2: Preprocessing (1 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå)
1. ‚è≥ Audio quality check
2. ‚è≥ Normalization
3. ‚è≥ Segmentation (3 sec, 50% overlap)
4. ‚è≥ Data augmentation (optional)
   - Pitch shifting (¬±2 semitones)
   - Time stretching (0.9-1.1√ó)
   - Add noise

### Phase 3: Feature Extraction (1 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå)
1. ‚è≥ Extract MFCC, Chroma, Spectral
2. ‚è≥ Verify feature quality
3. ‚è≥ Save feature vectors
4. ‚è≥ Create training/validation split

### Phase 4: Model Training (1-2 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå)
1. ‚è≥ Train baseline Random Forest
2. ‚è≥ Cross-validation
3. ‚è≥ Hyperparameter tuning
4. ‚è≥ Experiment with other models:
   - SVM
   - XGBoost
   - Neural Networks (CNN)

### Phase 5: Transcription (Optional, 2-3 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå)
1. ‚è≥ Test Basic Pitch on Thai music
2. ‚è≥ Fine-tune if needed
3. ‚è≥ Implement onset/pitch detection
4. ‚è≥ Validate against ‡πÇ‡∏ô‡πä‡∏ï‡∏•‡∏≤‡∏¢‡∏û‡∏¥‡∏ì

### Phase 6: Evaluation & Documentation (1 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå)
1. ‚è≥ Comprehensive testing
2. ‚è≥ Error analysis
3. ‚è≥ Documentation
4. ‚è≥ Demo preparation

---

## üìö ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°

### Datasets Download Links
- **NSynth:** https://magenta.withgoogle.com/datasets/nsynth
- **OpenMIC-2018:** https://github.com/cosmir/openmic-2018
- **FMA:** https://github.com/mdeff/fma
- **MusicNet:** https://benadar293.github.io/
- **Slakh2100:** https://github.com/KinWaiCheuk/slakh_loader

### Tools & Libraries
- **Basic Pitch:** https://github.com/spotify/basic-pitch
- **Omnizart:** https://github.com/Music-and-Culture-Technology-Lab/omnizart
- **librosa:** https://librosa.org/
- **mir_eval:** https://craffel.github.io/mir_eval/
- **pretty_midi:** https://craffel.github.io/pretty-midi/

### Research Papers
- **Basic Pitch Paper:** https://arxiv.org/abs/2203.09893
- **MT3:** https://arxiv.org/abs/2111.03017
- **YourMT3+:** https://arxiv.org/html/2407.04822v1
- **Thai Music System:** https://journal.iftawm.org/wp-content/uploads/2022/02/Garzoli_AAWM_Vol_4_2.pdf

### YouTube Playlists/Channels
- **‡∏°‡∏π‡∏ô‡∏°‡∏±‡∏á‡∏≠‡∏µ‡∏™‡∏≤‡∏ô:** ‡∏™‡∏≠‡∏ô‡∏û‡∏¥‡∏ì‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
- **‡∏î‡∏∏‡∏•‡∏¢‡πå‡πÄ‡∏û‡∏•‡∏á‡∏û‡∏¥‡∏ì:** ‡∏•‡∏≤‡∏¢‡∏û‡∏¥‡∏ì‡∏ï‡πà‡∏≤‡∏á ‡πÜ
- **‡∏™‡∏ï‡∏µ‡∏ü ‡∏ê‡∏¥‡∏ï‡∏¥‡∏ß‡∏±‡∏™‡∏™‡πå:** ‡πÇ‡∏ô‡πä‡∏ï‡∏û‡∏¥‡∏ì‡πÄ‡∏¢‡∏≠‡∏∞
- **M MUSIC GROUP:** ‡∏™‡∏≠‡∏ô‡πÅ‡∏ö‡∏ö‡∏°‡∏µ‡πÇ‡∏ô‡πä‡∏ï

---

## üîó Next Steps

### ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ (‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå‡∏ô‡∏µ‡πâ)
1. ‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏ô‡πä‡∏ï‡∏û‡∏¥‡∏ì‡∏à‡∏≤‡∏Å guitar285.wordpress.com
2. ‚è≥ ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ Basic Pitch ‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏¥‡∏ì
3. ‚è≥ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î FMA small subset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö
4. ‚è≥ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏° YouTube links ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö

### ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå‡∏´‡∏ô‡πâ‡∏≤
1. ‚è≥ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏•‡∏≠‡∏á yt-dlp
2. ‚è≥ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 10-20 ‡πÑ‡∏ü‡∏•‡πå
3. ‚è≥ ‡∏ó‡∏î‡∏•‡∏≠‡∏á pipeline ‡πÉ‡∏ô project ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
4. ‚è≥ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ AI Drive ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

### ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤
1. ‚è≥ ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö 100-200 samples
2. ‚è≥ Train baseline model
3. ‚è≥ Evaluate ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
4. ‚è≥ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥ transcription experiments

---

## üìû ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠

### Project Repository
- **GitHub:** kritsanan1/isan-instruments

### Useful Communities
- **ISMIR (International Society for Music Information Retrieval)**
- **Magenta Community**
- **Music Technology StackExchange**

---

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡∏ö‡∏Ñ‡πâ‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 24 ‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô 2025 
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ Isan Musical Instruments Classifier ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏≥‡∏ô‡∏∂‡∏á‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏≤‡∏£‡∏û‡∏ï‡πà‡∏≠‡∏ß‡∏±‡∏í‡∏ô‡∏ò‡∏£‡∏£‡∏°‡πÅ‡∏•‡∏∞‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏° AI

**‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏î‡∏¢:** AI Research Assistant
**‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå:** ‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏£‡∏±‡∏Å‡∏©‡πå‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏ö‡πâ‡∏≤‡∏ô‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ AI
